{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ticket Data Analysis\n",
    "\n",
    "This notebook demonstrates how to analyze the FreshService ticket data using Python's data science tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "First, let's import the necessary libraries and load our ticket data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Set plot styling\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"darkgrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define possible data paths to try\n",
    "possible_paths = [\n",
    "    # Original path\n",
    "    'data/fresh_service_tickets',\n",
    "    # JupyterLite files directory path\n",
    "    'files/data/fresh_service_tickets',\n",
    "    # Relative paths\n",
    "    '../data/fresh_service_tickets',\n",
    "    './data/fresh_service_tickets',\n",
    "    # Absolute path within JupyterLite\n",
    "    '/files/data/fresh_service_tickets'\n",
    "]\n",
    "\n",
    "# Load ticket data\n",
    "tickets = None\n",
    "for base_path in possible_paths:\n",
    "    try:\n",
    "        path1 = f\"{base_path}/Tickets_1.csv\"\n",
    "        path2 = f\"{base_path}/Tickets_2.csv\"\n",
    "        print(f\"Trying to load from: {path1}\")\n",
    "        \n",
    "        tickets1 = pd.read_csv(path1)\n",
    "        tickets2 = pd.read_csv(path2)\n",
    "        \n",
    "        # Combine the datasets\n",
    "        tickets = pd.concat([tickets1, tickets2], ignore_index=True)\n",
    "        print(f\"Successfully loaded {len(tickets)} tickets from {base_path}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load from {base_path}: {e}\")\n",
    "\n",
    "if tickets is None:\n",
    "    print(\"Failed to load ticket data from any location. Please check file paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "\n",
    "Let's take a look at our data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "if tickets is not None:\n",
    "    print(\"Dataset shape:\", tickets.shape)\n",
    "    print(\"\\nColumns:\")\n",
    "    for col in tickets.columns:\n",
    "        print(f\"- {col}\")\n",
    "\n",
    "    # Show the first few rows\n",
    "    tickets.head()\n",
    "else:\n",
    "    print(\"No data available to explore.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preparation\n",
    "\n",
    "Let's clean and prepare our data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime format\n",
    "if tickets is not None:\n",
    "    date_columns = ['created_time', 'resolved_time', 'closed_time', 'due_by_time', \n",
    "                    'initial_response_time', 'last_updated_time']\n",
    "\n",
    "    for col in date_columns:\n",
    "        if col in tickets.columns:\n",
    "            try:\n",
    "                tickets[col] = pd.to_datetime(tickets[col])\n",
    "            except Exception as e:\n",
    "                print(f\"Could not convert {col}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "if tickets is not None:\n",
    "    missing_data = tickets.isnull().sum()\n",
    "    missing_percent = (missing_data / len(tickets)) * 100\n",
    "\n",
    "    missing_stats = pd.DataFrame({\n",
    "        'Missing Values': missing_data,\n",
    "        'Percentage': missing_percent\n",
    "    })\n",
    "\n",
    "    # Display columns with missing values\n",
    "    missing_stats[missing_stats['Missing Values'] > 0].sort_values('Missing Values', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticket Analysis\n",
    "\n",
    "Now let's analyze the tickets by different dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tickets by Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tickets is not None and 'status' in tickets.columns:\n",
    "    # Count tickets by status\n",
    "    status_counts = tickets['status'].value_counts()\n",
    "    \n",
    "    # Create a pie chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "    plt.title('Ticket Distribution by Status')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"'status' column not found in the dataset or no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tickets by Priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tickets is not None and 'priority' in tickets.columns:\n",
    "    # Count tickets by priority\n",
    "    priority_counts = tickets['priority'].value_counts()\n",
    "    \n",
    "    # Create a bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=priority_counts.index, y=priority_counts.values)\n",
    "    plt.title('Ticket Distribution by Priority')\n",
    "    plt.xlabel('Priority')\n",
    "    plt.ylabel('Number of Tickets')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"'priority' column not found in the dataset or no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tickets by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tickets is not None and 'category' in tickets.columns:\n",
    "    # Get the top 10 categories\n",
    "    category_counts = tickets['category'].value_counts().head(10)\n",
    "    \n",
    "    # Create a horizontal bar chart\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(y=category_counts.index, x=category_counts.values)\n",
    "    plt.title('Top 10 Ticket Categories')\n",
    "    plt.xlabel('Number of Tickets')\n",
    "    plt.ylabel('Category')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"'category' column not found in the dataset or no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket Creation Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tickets is not None and 'created_time' in tickets.columns:\n",
    "    # Extract date from datetime\n",
    "    tickets['created_date'] = tickets['created_time'].dt.date\n",
    "    \n",
    "    # Count tickets by creation date\n",
    "    daily_tickets = tickets.groupby('created_date').size()\n",
    "    \n",
    "    # Create a line chart\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    daily_tickets.plot()\n",
    "    plt.title('Ticket Creation Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of Tickets')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Monthly ticket volume\n",
    "    tickets['created_month'] = tickets['created_time'].dt.to_period('M')\n",
    "    monthly_tickets = tickets.groupby('created_month').size()\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    monthly_tickets.plot(kind='bar')\n",
    "    plt.title('Monthly Ticket Volume')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Number of Tickets')\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"'created_time' column not found in the dataset or no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolution Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tickets is not None and all(col in tickets.columns for col in ['created_time', 'resolved_time']):\n",
    "    # Calculate resolution time in hours\n",
    "    tickets['resolution_time_hours'] = (tickets['resolved_time'] - tickets['created_time']).dt.total_seconds() / 3600\n",
    "    \n",
    "    # Filter out negative or extreme values\n",
    "    valid_resolution = tickets[(tickets['resolution_time_hours'] > 0) & (tickets['resolution_time_hours'] < 1000)]\n",
    "    \n",
    "    # Create a histogram\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(valid_resolution['resolution_time_hours'], bins=50, kde=True)\n",
    "    plt.title('Distribution of Ticket Resolution Time')\n",
    "    plt.xlabel('Resolution Time (hours)')\n",
    "    plt.ylabel('Number of Tickets')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Resolution time by priority\n",
    "    if 'priority' in tickets.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(x='priority', y='resolution_time_hours', data=valid_resolution)\n",
    "        plt.title('Resolution Time by Priority')\n",
    "        plt.xlabel('Priority')\n",
    "        plt.ylabel('Resolution Time (hours)')\n",
    "        plt.grid(True, axis='y')\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"'created_time' or 'resolved_time' columns not found in the dataset or no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Analysis\n",
    "\n",
    "Let's dive deeper into the data to extract more insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SLA Compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tickets is not None and 'first_response_status' in tickets.columns:\n",
    "    # Analyze SLA compliance for first response\n",
    "    sla_counts = tickets['first_response_status'].value_counts()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.pie(sla_counts, labels=sla_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    plt.axis('equal')\n",
    "    plt.title('First Response SLA Compliance')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"'first_response_status' column not found in the dataset or no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Requesters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tickets is not None and 'requester_name' in tickets.columns:\n",
    "    # Get top 10 requesters\n",
    "    top_requesters = tickets['requester_name'].value_counts().head(10)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(y=top_requesters.index, x=top_requesters.values)\n",
    "    plt.title('Top 10 Ticket Requesters')\n",
    "    plt.xlabel('Number of Tickets')\n",
    "    plt.ylabel('Requester')\n",
    "    plt.grid(True, axis='x')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"'requester_name' column not found in the dataset or no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tickets is not None and 'agents' in tickets.columns:\n",
    "    # Get top 10 agents\n",
    "    top_agents = tickets['agents'].value_counts().head(10)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(y=top_agents.index, x=top_agents.values)\n",
    "    plt.title('Top 10 Ticket Handlers')\n",
    "    plt.xlabel('Number of Tickets')\n",
    "    plt.ylabel('Agent')\n",
    "    plt.grid(True, axis='x')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"'agents' column not found in the dataset or no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provides a starting point for analyzing your ticket data. You can extend this analysis by:\n",
    "\n",
    "1. Adding more visualizations specific to your needs\n",
    "2. Performing correlation analysis between different metrics\n",
    "3. Conducting trend analysis over longer periods\n",
    "4. Implementing machine learning models for ticket classification or resolution time prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
